# yc-startup-rag-chatbot
ğŸš€ YC Startup RAG Chatbot

A Retrieval-Augmented Generation (RAG) chatbot trained on Y Combinatorâ€™s â€œHow to Start a Startupâ€ lectures.

This project is an end-to-end RAG system that allows users to ask questions about YCâ€™s Startup School lectures and get accurate, grounded answers with citations from the original transcript.
It uses:

Python

Ollama (local LLM inference)

BGE-M3 embeddings

Streamlit (interactive chat UI)

Custom chunking + vector search

Local Retrieval-Augmented Generation pipeline



---

ğŸ§  Features

âœ… Chunking & Embeddings

Lecture transcripts are chunked using a Recursive Character Text Splitter.

Embeddings generated using BGE-M3 via Ollama.

Stored efficiently in embeddings.joblib.


âœ… RAG Pipeline

Retrieve top-K most relevant chunks using cosine similarity.

Construct structured prompts using retrieved YC lecture content.

Generate grounded answers using lightweight local LLMs:

llama3.2:1b


âœ… Interactive Chat UI

Built with Streamlit, showing:

Chat messages

Retrieved lecture chunks (sources)

Clean and readable answers

Session chat history


âœ… Local, Privacy-Friendly & Fast

Everything runs fully offline using Ollama on your machine.


---

ğŸ“‚ Project Structure

â”œâ”€â”€ app.py                  # Streamlit chat application
â”œâ”€â”€ chunking.py             # Splits transcripts into chunks
â”œâ”€â”€ read_chunk.py           # Generates embeddings + saves joblib
â”œâ”€â”€ process_incoming.py     # CLI-based RAG pipeline
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â”œâ”€â”€ transcript/             # raw lecture transcripts (ignored)
â”œâ”€â”€ json/                   # chunk JSON files (ignored)
â”œâ”€â”€ embeddings.joblib       # embeddings (ignored)
â””â”€â”€ videos/, audios/        # raw data (ignored)


---

ğŸš€ Getting Started

1ï¸âƒ£ Clone the repository

git clone https://github.com/<your-username>/yc-startup-rag-chatbot.git
cd yc-startup-rag-chatbot


---

2ï¸âƒ£ Install dependencies

Create environment (optional):

conda create -n yc-rag python=3.10 -y
conda activate yc-rag

Install packages:

pip install -r requirements.txt


---

3ï¸âƒ£ Install and start Ollama

Download Ollama:
https://ollama.com/download

Serve models:

ollama pull bge-m3
ollama pull llama3.2:1b     # fastest
# or
ollama pull phi3            # best speed + quality

Start Ollama:

ollama serve


---

4ï¸âƒ£ Prepare Data

Chunk transcripts

python chunking.py

Generate embeddings

python read_chunk.py


---

5ï¸âƒ£ Run the Streamlit App

streamlit run app.py

Your browser will open the chatbot UI at:

http://localhost:8501


---

ğŸ§ª Example Questions

Try asking:

"What does Paul Graham say about generating startup ideas?"

"How should founders think about growth?"

"What is the most important quality in a co-founder?"


The app will show:

The answer

The exact lecture chunks used as context



---

ğŸ—ï¸ RAG Architecture

User Query
     â†“
Create Embedding (BGE-M3)
     â†“
Vector Search (Cosine Similarity)
     â†“
Retrieve Top-K Lecture Chunks
     â†“
Build Structured Prompt
     â†“
Local LLM (Llama3.2 / Phi3)
     â†“
Grounded Answer + Sources


---

ğŸ§© Technologies Used

Python

Streamlit

Ollama

BGE-M3 embeddings

Numpy / Pandas

Scikit-Learn

Joblib

---

ğŸ§‘â€ğŸ’» Author

Ashwani Jha
RAG Developer | Machine Learning | LLMs

LinkedIn: www.linkedin.com/in/ashwani-jha-03ab14311
